---
title: "Client Report - Show me!"
subtitle: "Unit 4 Task 3"
author: "Ezekial Curran"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
import torch
import torch.nn as nn
import torch.optim as optim
import polars as pl
import numpy as np
from lets_plot import *
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.inspection import permutation_importance
from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin
from sklearn.metrics import (
  classification_report,
  accuracy_score,
  recall_score,
  precision_score,
  f1_score,
  r2_score,
  median_absolute_error,
  mean_absolute_error,
  mean_squared_error,
  root_mean_squared_error
  )

LetsPlot.setup_html(isolated_frame=True)
```


```{python}
# import your data here using pandas and the URL
url1 = "https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_ml/dwellings_ml.csv"
url2 = "https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_neighborhoods_ml/dwellings_neighborhoods_ml.csv"
url3 = "https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_denver/dwellings_denver.csv"
url4 = "https://github.com/byuidatascience/data4dwellings/blob/master/data.md"

df = pl.read_csv('dwellings_ml.csv')
```

## Supplimental Code

```{python}
class Neural_Net(nn.Module):
  def __init__(self, input_size, shallow=True):
    super(Neural_Net, self).__init__()
    if shallow:
      self.net = nn.Sequential(
        nn.Linear(input_size, 32),
        nn.ReLU(),
        nn.Linear(32, 1)
      )
    else:
      self.net = nn.Sequential(
        nn.Linear(input_size, 32),
        nn.ReLU(),
        nn.Dropout(0.1),

        nn.Linear(32, 16),
        nn.ReLU(),
        nn.Dropout(0.1),

        nn.Linear(16, 1)
        # self.relu3 = nn.ReLU()
        # self.dropout3 = nn.Dropout(0.1)

        # self.fc4 = nn.Linear(4, 2)
        # self.relu4 = nn.ReLU()
        # self.dropout4 = nn.Dropout(0.1)

        # self.fc5 = nn.Linear(2, 1)
      )
  
  def forward(self, x):
    return self.net(x)

class TorchModelWrapper(BaseEstimator):
  def __init__(self, model, device, task="classification", scorer="f1_score"):
    self.model = model
    self.device = device
    self.task = task # 'classification' or 'regression'
    self.scorer = scorer

  def fit(self, X, y):
    return self

  def predict(self, X):
    self.model.eval()
    with torch.no_grad():
      X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)
      outputs = self.model(X_tensor)

      if self.task == "regression":
        return outputs.cpu().numpy().flatten()
      elif self.task == "classification":
        if outputs.shape[1] == 1:
          probs = torch.sigmoid(outputs).cpu().numpy()
          return (probs >= 0.5).astype(int).flatten()
        else:
          return torch.argmax(outputs, dim=1).cpu().numpy()
      else:
        raise ValueError(f"Unsupported task type: {self.task}\nOnly two types of tasks are available: regression and classification (default)")

  def score(self, X, y):
    y_pred = self.predict(X)

    if self.scorer == "f1_score":
      return f1_score(y, y_pred)
    elif self.scorer == "accuracy_score":
      return accuracy_score(y, y_pred)
    elif self.scorer == "meanAE":
      return mean_absolute_error(y, y_pred)
    elif self.scorer == "medAE":
      return median_absolute_error(y, y_pred)
    elif self.scorer == "MSE":
      return mean_squared_error(y, y_pred)
    elif self.scorer == "RMSE":
      return root_mean_squared_error(y, y_pred)
    elif self.scorer == "r2_score":
      return r2_score(y, y_pred)
    elif self.scorer == "recall_score":
      return recall_score(y, y_pred)
    elif self.scorer == "precision_score":
      return precision_score(y, y_pred)
    else:
      raise ValueError(f"Unsupported scoring method: {self.scorer}")

def train_model(model, name, X_train, X_test, y_train, y_test, epochs=1000):
  criterion = nn.BCEWithLogitsLoss()
  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
  train_losses = []
  test_accuracies = []
  f1_scores = []
  # r2_scores = [] # Only for regression tasks not classification
  # rmses = [] # Only for regression tasks not classification

  y_true = y_test.int().cpu().numpy() if torch.cuda.is_available() else y_test

  print(f"Training: {name}")
  for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()
    output = model(X_train)
    loss = criterion(output, y_train)
    loss.backward()
    optimizer.step()
    train_losses.append(loss.item())

    model.eval()
    with torch.no_grad():
      probs = torch.sigmoid(model(X_test))
      preds = (probs >=0.5).int().cpu().numpy() if torch.cuda.is_available() else (probs >= 0.5).float()
      accuracy = (preds == y_true).mean().item()
      f1 = f1_score(y_true, preds)
      # r2 = r2_score(y_true, preds)
      # rmse = root_mean_squared_error(y_true, preds)
      test_accuracies.append(accuracy)
      f1_scores.append(f1)
      # r2_scores.append(r2)
      # rmses.append(rmse)


    if (epoch+1) % (epochs / 10) == 0:
      print(f"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.3f}, F1: {f1:.3f}")

  with torch.no_grad():
    probs = torch.sigmoid(model(X_test))
    preds = (probs >=0.5).int().cpu().numpy() if torch.cuda.is_available() else (probs >= 0.5).float()
    
    y_true = y_test.int().cpu().numpy() if torch.cuda.is_available() else y_tst_tensor

  print(classification_report(y_true, preds))
  
  return train_losses, test_accuracies, f1_scores

# To use integrated gradients, the model needs to be differential
def integrated_gradients(model, inputs, baseline=None, steps=50):
  if baseline is None:
    baseline = torch.zeros_like(inputs)

  inputs = inputs.requires_grad_()
  scaled_inputs = [baseline + (float(i) / steps) * (inputs - baseline) for i in range(steps + 1)]
  grad = []

  for i in scaled_inputs:
    model.zero_grad()
    out = model(i)
    out = out.squeeze()
    out.backward(troch.ones_like(out))
    grads.append(i.grad.detach().clone())
    i.grad.zero_()

  avg_grads = torch.stack(grads).mean(dim=0)
  integrated_grads = (inputs - baseline) * avg_grads
  return integrated_grads

if (torch.cuda.is_available()):
  print(f"CUDA is available, using the GPU")
  print(torch.cuda.get_device_name(0))
  device = torch.device("cuda")
  torch.cuda.manual_seed(117)
else:
  print(f"CUDA is not available, using the CPU")
  device = torch.device("cpu")
  torch.manual_seed(117)

X = df.drop(["parcel", "before1980", "yrbuilt"]).to_numpy()
y = df.select(["before1980"]).to_numpy()

scaler = StandardScaler()
X = scaler.fit_transform(X)

X_trn, X_tst, y_trn, y_tst = train_test_split(X, y, test_size=0.2, random_state=117)

X_trn_tensor = torch.tensor(X_trn, dtype=torch.float32)
y_trn_tensor = torch.tensor(y_trn, dtype=torch.float32).view(-1, 1)
X_tst_tensor = torch.tensor(X_tst, dtype=torch.float32)
y_tst_tensor = torch.tensor(y_tst, dtype=torch.float32).view(-1, 1)

if torch.cuda.is_available():
  print(f"Moving Tensors to the GPU")
  X_trn_tensor = X_trn_tensor.to(device)
  y_trn_tensor = y_trn_tensor.to(device)
  X_tst_tensor = X_tst_tensor.to(device)
  y_tst_tensor = y_tst_tensor.to(device) 
```


## QUESTION 1

__Create 2-3 charts that evaluate the relationships between each of the top 2 or 3 most important variables (as found in Unit 4 Task 2) and the year the home was built.__ Describe what you learn from the charts about how that variable is related to year built.   

_type your write-up and analysis here_
_For example, how does a particular feature determine whether a house is built before 1980 or not. Does having a garage mean the house is before 1980._

```{python}
# Include and execute your code here
num_epochs = 100
shallow_mdl = Neural_Net(input_size=X.shape[1])
deep_mdl = Neural_Net(input_size=X.shape[1], shallow=False)

if torch.cuda.is_available():
  print(f"Moving the models to the GPU")
  shallow_mdl = shallow_mdl.to(device)
  deep_mdl = deep_mdl.to(device)


loss_shallow, acc_shallow, f1_shallow = train_model(shallow_mdl, "Shallow", X_trn_tensor, X_tst_tensor, y_trn_tensor, y_tst_tensor, epochs=num_epochs)
loss_deep, acc_deep, f1_deep = train_model(deep_mdl, "Deep", X_trn_tensor, X_tst_tensor, y_trn_tensor, y_tst_tensor, epochs=num_epochs)

res = pl.DataFrame({
  "epoch": epochs,
  "loss_shallow": loss_shallow,
  "loss_deep": loss_deep,
  "acc_shallow": acc_shallow,
  "acc_deep": acc_deep,
  "f1_shallow": f1_shallow,
  "f1_deep": f1_deep
})

kf = KFold(n_splits=5, shuffle=True, random_state=117)

shall_losses = np.zeros(num_epochs)
shall_accs = np.zeros(num_epochs)
shall_f1 = np.zeros(num_epochs)
deep_losses = np.zeros(num_epochs)
deep_accs = np.zeros(num_epochs)
deep_f1 = np.zeros(num_epochs)

for fold, (train_idx, val_idx) in enumerate(kf.split(X_trn_tensor)):
  print(f"Fold {fold + 1}")
  X_train = X_trn_tensor[train_idx]
  X_val = X_trn_tensor[val_idx]
  y_train = y_trn_tensor[train_idx]
  y_val = y_trn_tensor[val_idx]

  shall_model = Neural_Net(input_size=X_train.shape[1])
  deep_model = Neural_Net(input_size=X_train.shape[1])

  if torch.cuda.is_available():
    shall_model = shall_model.to(device)
    deep_model = deep_model.to(device)

  s_loss, s_acc, s_f1 = train_model(shall_model, "Shallow", X_train, X_val, y_train, y_val, num_epochs)
  shall_losses += np.array(s_loss)
  shall_accs += np.array(s_acc)
  shall_f1 += np.array(s_f1)

  d_loss, d_acc, d_f1 = train_model(deep_model, "Deep", X_train, X_val, y_train, y_val, num_epochs)
  deep_losses += np.array(d_loss)
  deep_accs += np.array(d_acc)
  deep_f1 += np.array(d_f1)

shall_losses /= 5
shall_accs /= 5
shall_f1 /= 5
deep_losses /= 5
deep_accs /= 5
deep_f1 /= 5

epochs = range(num_epochs)
cv_res = pl.DataFrame({
  "epoch": epochs,
  "loss_shallow": shall_losses,
  "loss_deep": deep_losses,
  "accuracy_shallow": shall_accs,
  "accuracy_deep": deep_accs,
  "f1_shallow": shall_f1,
  "f1_deep": deep_f1
})
```

```{python}
loss_unpivot = res.unpivot(index='epoch', on=['loss_shallow', 'loss_deep'], variable_name='mdl', value_name='value')
acc_f1_unpivot = res.unpivot(index='epoch', on=['acc_shallow', 'acc_deep', 'f1_shallow', 'f1_deep'], variable_name='mdl', value_name='value')

loss_graph = (
    ggplot(data=loss_unpivot)
    + geom_line(mapping = aes(x = 'epoch', y = 'value', color='mdl'))
    + labs(
      title="Loss Over Time",
      x="Epochs",
      y="Loss",
      color="Model"
    )
    + theme(
        panel_background=element_rect(fill='gray'),
        plot_background=element_rect(fill='gray'),
        panel_grid_major=element_rect(fill='gray'),
        legend_background=element_rect(fill='gray'),
        axis_text=element_text(color='white'),
        axis_title=element_text(color='white'),
        plot_title=element_text(color='white'),
        plot_subtitle=element_text(color='white'),
        legend_text=element_text(color='white'),
        legend_title=element_text(color='white'),
        label_text=element_text(color='white')
    )
    + ggsize(1600, 900)
)

acc_f1_graph = (
  ggplot(data=acc_f1_unpivot)
  + geom_line(mapping = aes(x = 'epoch', y = 'value', color='mdl'), size=1.5)
  + labs(
    title="Accuracy and F1 Score Over Time",
    x="Epochs",
    y="Accuracy",
    color="Model"
  )
  + theme(
      panel_background=element_rect(fill='gray'),
      plot_background=element_rect(fill='gray'),
      panel_grid_major=element_rect(fill='gray'),
      legend_background=element_rect(fill='gray'),
      axis_text=element_text(color='white'),
      axis_title=element_text(color='white'),
      plot_title=element_text(color='white'),
      plot_subtitle=element_text(color='white'),
      legend_text=element_text(color='white'),
      legend_title=element_text(color='white'),
      label_text=element_text(color='white')
  )
  + ggsize(1600, 900)
)
display(loss_graph)
display(acc_f1_graph)
```

```{python}
cv_loss_unpivot = cv_res.unpivot(index='epoch', on=['loss_shallow', 'loss_deep'], variable_name='mdl', value_name='value')
cv_acc_f1_unpivot = cv_res.unpivot(index='epoch', on=['accuracy_shallow', 'accuracy_deep', 'f1_shallow', 'f1_deep'], variable_name='mdl', value_name='value')

cv_loss_graph = (
    ggplot(data=cv_loss_unpivot)
    + geom_line(mapping = aes(x = 'epoch', y = 'value', color='mdl'))
    + labs(
      title="Cross Validation Loss Over Time",
      x="Epochs",
      y="Loss",
      color="Model"
    )
    + theme(
        panel_background=element_rect(fill='gray'),
        plot_background=element_rect(fill='gray'),
        panel_grid_major=element_rect(fill='gray'),
        legend_background=element_rect(fill='gray'),
        axis_text=element_text(color='white'),
        axis_title=element_text(color='white'),
        plot_title=element_text(color='white'),
        plot_subtitle=element_text(color='white'),
        legend_text=element_text(color='white'),
        legend_title=element_text(color='white'),
        label_text=element_text(color='white')
    )
    + ggsize(1600, 900)
)

cv_acc_f1_graph = (
  ggplot(data=cv_acc_f1_unpivot)
  + geom_line(mapping = aes(x = 'epoch', y = 'value', color='mdl'), size=1.5)
  + labs(
    title="Cross Validation Accuracy and F1 Score Over Time",
    x="Epochs",
    y="Accuracy",
    color="Model"
  )
  + theme(
      panel_background=element_rect(fill='gray'),
      plot_background=element_rect(fill='gray'),
      panel_grid_major=element_rect(fill='gray'),
      legend_background=element_rect(fill='gray'),
      axis_text=element_text(color='white'),
      axis_title=element_text(color='white'),
      plot_title=element_text(color='white'),
      plot_subtitle=element_text(color='white'),
      legend_text=element_text(color='white'),
      legend_title=element_text(color='white'),
      label_text=element_text(color='white')
  )
  + ggsize(1600, 900)
)
display(cv_loss_graph)
display(cv_acc_f1_graph)
```


## QUESTION 2

__Create at least one other chart to examine a variable(s) you thought might be important but apparently was not. The chart should show its relationship to the year built.__ Describe what you learn from the chart about how that variable is related to year built. Explain why you think it was not (very) important in the model.

_type your write-up and analysis here_

```{python}
# Include and execute your code here


```