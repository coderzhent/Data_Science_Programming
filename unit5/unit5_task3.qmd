---
title: "Client Report - Star Wars for Dummies"
subtitle: "Unit 5 Task 3"
author: "Ezekial Curran"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
import polars as pl
import numpy as np
from lets_plot import *
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import (
  classification_report, 
  accuracy_score, 
  recall_score, 
  precision_score, 
  f1_score
  )
# add the additional libraries you need to import for ML here

LetsPlot.setup_html(isolated_frame=True)
```


```{python}
# import your data here using pandas and the URL
url = "https://github.com/fivethirtyeight/data/raw/master/star-wars-survey/StarWars.csv"
df = pl.read_csv("StarWars.csv")

df_clean = df.rename({
    df.columns[1]: "seen",
    df.columns[2]: "fan",
    **{df.columns[i]: f"seen_epi_{['i', 'ii', 'iii', 'iv', 'v', 'vi'][i - 3]}" for i in range(3, 9)},
    **{df.columns[i]: f"rank_epi_{['i', 'ii', 'iii', 'iv', 'v', 'vi'][i - 9]}" for i in range(9, 15)},
    **{df.columns[i]: df[df.columns[i]][0].lower().replace(' ', '_') for i in range(15, 29)},
    df.columns[29]: "shot_first",
    df.columns[30]: "ex_uni",
    df.columns[31]: "fan_ex_uni",
    df.columns[32]: "fan_star_trek",
    **{df.columns[i]: df.columns[i].lower().replace(' ', '_') for i in range(33, 37)},
    df.columns[37]: "location"
})

df_clean = df_clean[1:]
```

## QUESTION 1

1. __Prep the data for machine learning:__
    a. Create your target (also known as “y” or “label”) column based on the new income range column  
    a. One-hot encode all remaining categorical columns 

_type your write-up and analysis here_

```{python}
# Include and execute your code here

df_clean = df_clean.with_columns(
  pl.when((pl.col('age') == "> 60"))
  .then(4)
  .when((pl.col('age') == "45-60"))
  .then(3)
  .when((pl.col('age') == "30-44"))
  .then(2)
  .when((pl.col('age') == "18-29"))
  .then(1)
  .otherwise(0)
  .alias("age_num")
)

df_clean = df_clean.with_columns(
  pl.when((pl.col('education') == "Graduate degree"))
  .then(5)
  .when((pl.col('education') == "Bachelor degree"))
  .then(4)
  .when((pl.col('education') == "Some college or Associate degree"))
  .then(3)
  .when((pl.col('education') == "High school degree"))
  .then(2)
  .when((pl.col('education') == "Less than high school degree"))
  .then(1)
  .otherwise(0)
  .alias("education_num")
)

df_clean = df_clean.with_columns(
  pl.when((pl.col('household_income') == '$150,000+'))
  .then(5)
  .when((pl.col('household_income') == '$100,000 - $149,999'))
  .then(4)
  .when((pl.col('household_income') == '$50,000 - $99,999'))
  .then(3)
  .when((pl.col('household_income') == '$25,000 - $49,999'))
  .then(2)
  .when((pl.col('household_income') == '$0 - $24,999'))
  .then(1)
  .otherwise(0)
  .alias("income")
)

df_clean = df_clean.with_columns(
  pl.when((pl.col(df_clean.columns[i]) == "Very favorably"))
  .then(6)
  .when((pl.col(df_clean.columns[i]) == "Somewhat favorably"))
  .then(5)
  .when((pl.col(df_clean.columns[i]) == "Neither favorably nor unfavorably (neutral)"))
  .then(4)
  .when((pl.col(df_clean.columns[i]) == "Somewhat unfavorably"))
  .then(3)
  .when((pl.col(df_clean.columns[i]) == "Very unfavorably"))
  .then(2)
  .when((pl.col(df_clean.columns[i]) == "Unfamiliar (N/A)"))
  .then(1)
  .otherwise(0)
  .alias(df_clean.columns[i]) for i in range(15, 29)
)

cat_cols = ['rank_epi_i', 'rank_epi_ii', 'rank_epi_iii', 'rank_epi_iv', 'rank_epi_v', 'rank_epi_vi', 'seen', 'fan', 'seen_epi_i', 'seen_epi_ii', 'seen_epi_iii', 'seen_epi_iv', 'seen_epi_v', 'seen_epi_vi', 'shot_first', 'ex_uni', 'fan_ex_uni', 'fan_star_trek', 'gender', 'location']
df_clean = df_clean.drop(['age', 'education', 'household_income'])

enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
enc_ar = enc.fit_transform(df_clean[cat_cols])
enc_cols = list(enc.get_feature_names_out(cat_cols))
enc_df = pl.DataFrame(enc_ar, schema=enc_cols)
df_tot = pl.concat([df_clean.drop(cat_cols), enc_df], how='horizontal')


X = df_tot.drop(['RespondentID', 'income'])
y = df_tot.select('income')
```


## QUESTION 2

1. __Build a machine learning model that predicts whether a person makes at least $50k. Describe your model and report the accuracy.__

The classification of 3, 4, and 5 are all income ranges that are at least $50k. The model learned this very poorly. The accuracy based on the test is about 37%. This is very likely due to the significant amount of missing data present in the dataset. 

```{python}
# Include and execute your code here
rnd = 343
X_trn, X_tst, y_trn, y_tst = train_test_split(X, y, random_state=rnd, test_size=0.2)

model = GradientBoostingClassifier()
model.fit(X_trn, y_trn)
pred = model.predict(X_tst)
print(classification_report(y_tst, pred))
```